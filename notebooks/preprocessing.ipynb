{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from pymmseqs.commands import easy_cluster\n",
    "import os\n",
    "import re"
   ],
   "id": "f74249d83a995882",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Toxins\n",
    "(taxonomy_id:33208) AND (cc_tissue_specificity:venom) AND (reviewed:true) AND (keyword:KW-0800) AND (fragment:false)"
   ],
   "id": "69c97c8b2e6f3af4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tox = pd.read_csv('../data/raw/tox.tsv', sep='\\t')\n",
    "tox = tox.dropna(subset=[\"Protein families\"])\n",
    "\n",
    "tox"
   ],
   "id": "4ec5111cfca456ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tox['Protein families'] = tox['Protein families'].str.split(',').str[0]\n",
    "tox['Protein families'] = tox['Protein families'].str.split(';').str[0]"
   ],
   "id": "65b617b59d1a7232",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tox['Protein families'] = tox['Protein families'].replace('I1 superfamily', 'Conotoxin I1 superfamily')\n",
    "tox['Protein families'] = tox['Protein families'].replace('O1 superfamily', 'Conotoxin O1 superfamily')\n",
    "tox['Protein families'] = tox['Protein families'].replace('O2 superfamily', 'Conotoxin O2 superfamily')\n",
    "tox['Protein families'] = tox['Protein families'].replace('E superfamily', 'Conotoxin E superfamily')\n",
    "tox['Protein families'] = tox['Protein families'].replace('F superfamily', 'Conotoxin F superfamily')\n",
    "tox['Protein families'] = tox['Protein families'].replace('Conotoxin M family', 'Conotoxin M superfamily')\n",
    "tox['Protein families'] = tox['Protein families'].replace('Conotoxin B2 family', 'Conotoxin B2 superfamily')\n",
    "tox['Protein families'] = tox['Protein families'].replace('Conotoxin O1 family', 'Conotoxin O1 superfamily')\n",
    "tox['Protein families'] = tox['Protein families'].replace('Conotoxin O2 family', 'Conotoxin O2 superfamily')"
   ],
   "id": "7c3dbd8e02ec9fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mapping = {\n",
    "    r'Conotoxin.*': 'Conotoxin family',\n",
    "    r'Neurotoxin.*': 'Neurotoxin family',\n",
    "    r'Scoloptoxin.*|Scolopendra.*': 'Scoloptoxin family',\n",
    "    r'Caterpillar.*': 'Caterpillar family',\n",
    "    r'Teretoxin.*': 'Teretoxin family',\n",
    "    r'Limacoditoxin.*': 'Limacoditoxin family',\n",
    "    r'Scutigerotoxin.*': 'Scutigerotoxin family',\n",
    "    r'Cationic peptide.*': 'Cationic peptide family',\n",
    "    r'Formicidae venom.*': 'Formicidae venom family',\n",
    "    r'Bradykinin-potentiating peptide family|Natriuretic peptide family': 'Natriuretic, Bradykinin potentiating peptide family',\n",
    "    r'.*phospholipase.*|.*Phospholipase.*': 'Phospholipase family'\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "for pattern, replacement in mapping.items():\n",
    "    tox['Protein families'] = tox['Protein families'].str.replace(pattern, replacement, regex=True)\n",
    "\n",
    "# everything with less than 3 samples is \"other\"\n",
    "tox[\"Protein families\"] = tox[\"Protein families\"].where(tox[\"Protein families\"].map(tox[\"Protein families\"].value_counts()) >= 10, \"other\")\n",
    "\n",
    "tox['Protein families'].value_counts()"
   ],
   "id": "205c453acfd5dd83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Non-Toxins\n",
    "(taxonomy_id:33208) AND (reviewed:true) AND (fragment:false) NOT (keyword:KW-0800) AND ((existence:1) OR (existence:2))"
   ],
   "id": "56905ed956085503"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nontox = pd.read_csv('../data/raw/nontox.tsv', sep='\\t')\n",
    "\n",
    "mask = nontox[\"Sequence\"].str.len() <= 2000\n",
    "removed = (~mask).sum()\n",
    "\n",
    "nontox = nontox[mask].reset_index(drop=True)\n",
    "\n",
    "nontox"
   ],
   "id": "bd735e9a12741e57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fasta Generation",
   "id": "a06152a19c57315b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def write_fasta(df, filename):\n",
    "    \"\"\"Writes a DataFrame to a FASTA file.\"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(f\">{row['Entry']}\\n{row['Sequence']}\\n\")\n",
    "\n",
    "write_fasta(tox, \"../data/raw/tox.fasta\")\n",
    "write_fasta(nontox, \"../data/raw/nontox.fasta\")"
   ],
   "id": "a9cda89593a1ce6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Remove SPs",
   "id": "6592f5d4fbae204b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!signalp6 --fastafile ../data/raw/tox.fasta --output_dir ../data/sp6/tox/ --organism eukarya --mode fast --model_dir /Users/selin/Desktop/Uni/signalp6/signalp-6-package/models/",
   "id": "11d25d0e48a81a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!signalp6 --fastafile ../data/nontox.fasta --output_dir ../data/sp6/nontox/ --organism eukarya --mode fast --model_dir /Users/selin/Desktop/Uni/signalp6/signalp-6-package/models/",
   "id": "27251f00bf54510e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fasta_to_dataframe(fasta_file):\n",
    "    records = SeqIO.parse(fasta_file, \"fasta\")\n",
    "    data = []\n",
    "\n",
    "    for record in records:\n",
    "        id_part = record.id.split('|')[-1]\n",
    "        data.append({\"identifier\": id_part, \"Sequence\": str(record.seq)})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# SignalP6 all (processed) sequences\n",
    "proc_tox = fasta_to_dataframe(\"../data/sp6/tox/processed_entries.fasta\")\n",
    "proc_nontox = fasta_to_dataframe(\"../data/sp6/nontox/processed_entries.fasta\")\n",
    "#proc_tox = proc_tox.rename(columns={'Sequence': 'Sequence'})\n",
    "#proc"
   ],
   "id": "359e98919b17aa97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proc_tox",
   "id": "ca6a55dd8c20e348",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gff3_tox = pd.read_csv('../data/sp6/tox/output.gff3', sep='\\t', comment='#', header=None)\n",
    "gff3_nontox = pd.read_csv('../data/sp6/nontox/output.gff3', sep='\\t', comment='#', header=None)\n",
    "\n",
    "cols = [\n",
    "    'identifier', 'source', 'feature_type', 'start', 'end',\n",
    "    'score', 'strand', 'phase', 'attributes'\n",
    "]\n",
    "gff3_tox.columns = cols\n",
    "gff3_nontox.columns = cols\n",
    "\n",
    "def extract_seqid(full_seqid):\n",
    "    return full_seqid.split('|')[-1].split(' ')[0]\n",
    "\n",
    "gff3_tox['identifier'] = gff3_tox['identifier'].apply(extract_seqid)\n",
    "gff3_nontox['identifier'] = gff3_nontox['identifier'].apply(extract_seqid)\n",
    "\n",
    "gff3_tox = pd.merge(gff3_tox, proc_tox, on='identifier')\n",
    "gff3_nontox = pd.merge(gff3_nontox, proc_nontox, on='identifier')"
   ],
   "id": "31434d3f76ba8ed1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gff3_tox[gff3_tox['score'] < 0.8]",
   "id": "1a3ee0aa55dbef89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### merge with SP6 predictions",
   "id": "d6ce61b5375190bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Merge with tox, replacing 'Sequence' where Entry matches\n",
    "\n",
    "filtered = gff3_tox[gff3_tox['score'] > 0.8][['identifier', 'Sequence']]\n",
    "filtered = filtered.rename(columns={'identifier': 'Entry'})\n",
    "tox.update(filtered.set_index('Entry'))\n",
    "\n",
    "filtered = gff3_nontox[gff3_nontox['score'] > 0.8][['identifier', 'Sequence']]\n",
    "filtered = filtered.rename(columns={'identifier': 'Entry'})\n",
    "nontox.update(filtered.set_index('Entry'))"
   ],
   "id": "a54efa38a141d9a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "write_fasta(tox, \"../data/interm/tox_noSP.fasta\")\n",
    "write_fasta(nontox, \"../data/interm/nontox_noSP.fasta\")"
   ],
   "id": "61d4c872bf594d12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Clustering\n",
    "### run mmseqs2 90% sequence similarity clustering per protein family"
   ],
   "id": "ce8c458677ae1813"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "out_dir = \"../data/families/\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    return re.sub(r\"[^a-zA-Z0-9_-]\", \"_\", name)\n",
    "\n",
    "failed = []\n",
    "\n",
    "for family, group in tox.groupby(\"Protein families\"):\n",
    "    safe_family = sanitize_filename(family)\n",
    "\n",
    "    fasta_path = os.path.join(out_dir, f\"{safe_family}.fasta\")\n",
    "    write_fasta(group, fasta_path)\n",
    "\n",
    "    # Create family-specific mmseqs directory\n",
    "    family_mmseqs_dir = os.path.join(\"/Users/selin/PycharmProjects/ToxFam/data/mmseqs\", safe_family)\n",
    "    os.makedirs(family_mmseqs_dir, exist_ok=True)\n",
    "\n",
    "    cluster_prefix = os.path.join(family_mmseqs_dir, \"cluster\")\n",
    "    tmp_dir = os.path.join(family_mmseqs_dir, \"tmp\")\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        easy_cluster(\n",
    "            fasta_files=fasta_path,\n",
    "            cluster_prefix=cluster_prefix,\n",
    "            tmp_dir=tmp_dir,\n",
    "            min_seq_id=0.9\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping {safe_family} due to error: {e}\")\n",
    "        failed.append((fasta_path, cluster_prefix, tmp_dir))\n",
    "\n",
    "# Print mmseqs commands for failures\n",
    "if failed:\n",
    "    print(\"\\n🔁 Manual mmseqs2 commands for failed entries:\\n\")\n",
    "    for fasta, out, tmp in failed:\n",
    "        print(f\"mmseqs easy-cluster {fasta} {out} {tmp} --min-seq-id 0.9\")"
   ],
   "id": "e948fa9640609ce2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mmseqs_base_dir = \"/Users/selin/PycharmProjects/ToxFam/data/mmseqs\"\n",
    "rep_seqs = []\n",
    "\n",
    "# Go through each family subdirectory (excluding \"nontox\")\n",
    "for family_dir in os.listdir(mmseqs_base_dir):\n",
    "    if family_dir == \"nontox\":\n",
    "        continue\n",
    "\n",
    "    full_path = os.path.join(mmseqs_base_dir, family_dir)\n",
    "    if not os.path.isdir(full_path):\n",
    "        continue\n",
    "\n",
    "    rep_fasta = os.path.join(full_path, \"cluster_rep_seq.fasta\")\n",
    "    if not os.path.exists(rep_fasta):\n",
    "        continue\n",
    "\n",
    "    # Parse FASTA and collect entries\n",
    "    for record in SeqIO.parse(rep_fasta, \"fasta\"):\n",
    "        rep_seqs.append({\n",
    "            \"Entry\": record.id,\n",
    "            \"Sequence\": str(record.seq),\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "rep_df = pd.DataFrame(rep_seqs).merge(tox[[\"Entry\", \"Protein families\"]], on=\"Entry\", how=\"left\")\n",
    "rep_df"
   ],
   "id": "123dcc363520815f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rep_df[\"Protein families\"] = rep_df[\"Protein families\"].where(rep_df[\"Protein families\"].map(rep_df[\"Protein families\"].value_counts()) >= 3, \"other\")\n",
    "rep_df[\"Protein families\"].value_counts()"
   ],
   "id": "f2402e3e5b2206fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train-Val-Test sets with 70:15:15 split",
   "id": "629adc507d8412df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure 'Protein families' is split only if not already a list\n",
    "rep_df['Protein families'] = rep_df['Protein families'].apply(lambda x: x.split(',') if isinstance(x, str) else x)\n",
    "\n",
    "# Create binary indicator matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(rep_df['Protein families'])\n",
    "\n",
    "# Save label classes (optional)\n",
    "label_classes = mlb.classes_\n",
    "\n",
    "# Train+val vs test split (test=15%)\n",
    "msss1 = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
    "idx_train_val, idx_test = next(msss1.split(rep_df, y))\n",
    "\n",
    "rep_df_train_val = rep_df.iloc[idx_train_val].copy()  # add .copy() here\n",
    "y_train_val = y[idx_train_val]\n",
    "\n",
    "# Train vs val split (val = 15% / (1-0.15) ~0.176 of train_val)\n",
    "val_size = 0.15 / (1 - 0.15)\n",
    "msss2 = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=42)\n",
    "idx_train, idx_val = next(msss2.split(rep_df_train_val, y_train_val))\n",
    "\n",
    "train_df = rep_df_train_val.iloc[idx_train].copy()  # add .copy() here\n",
    "val_df = rep_df_train_val.iloc[idx_val].copy()      # add .copy() here\n",
    "test_df = rep_df.iloc[idx_test].copy()              # add .copy() here\n",
    "\n",
    "# Join lists back to strings with .loc\n",
    "train_df.loc[:, 'Protein families'] = train_df['Protein families'].apply(lambda x: ','.join(x) if isinstance(x, list) else x)\n",
    "val_df.loc[:, 'Protein families'] = val_df['Protein families'].apply(lambda x: ','.join(x) if isinstance(x, list) else x)\n",
    "test_df.loc[:, 'Protein families'] = test_df['Protein families'].apply(lambda x: ','.join(x) if isinstance(x, list) else x)"
   ],
   "id": "20037ddeca7a6c13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_split_sizes(train_df, val_df, test_df, total_df):\n",
    "    print(f\"Train size: {len(train_df)} ({len(train_df)/len(total_df)*100:.2f}%)\")\n",
    "    print(f\"Validation size: {len(val_df)} ({len(val_df)/len(total_df)*100:.2f}%)\")\n",
    "    print(f\"Test size: {len(test_df)} ({len(test_df)/len(total_df)*100:.2f}%)\")\n",
    "print_split_sizes(train_df, val_df, test_df, rep_df)"
   ],
   "id": "569b14f623d58372",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_protein_family_distribution(train_df, val_df, test_df):\n",
    "    def get_family_percentages(df):\n",
    "        return df['Protein families'].str.split(',').explode().value_counts(normalize=True).sort_index()\n",
    "\n",
    "    train_pct = get_family_percentages(train_df)\n",
    "    val_pct = get_family_percentages(val_df)\n",
    "    test_pct = get_family_percentages(test_df)\n",
    "\n",
    "    all_families = sorted(set(train_pct.index) | set(val_pct.index) | set(test_pct.index))\n",
    "\n",
    "    train_pct = train_pct.reindex(all_families, fill_value=0)\n",
    "    val_pct = val_pct.reindex(all_families, fill_value=0)\n",
    "    test_pct = test_pct.reindex(all_families, fill_value=0)\n",
    "\n",
    "    df_pct = pd.DataFrame({\n",
    "        'Train': train_pct,\n",
    "        'Validation': val_pct,\n",
    "        'Test': test_pct\n",
    "    }).T\n",
    "\n",
    "    # Generate rainbow colormap with number of families colors\n",
    "    num_colors = len(all_families)\n",
    "    cmap = cm.get_cmap('rainbow', num_colors)\n",
    "    colors = [cmap(i) for i in range(num_colors)]\n",
    "\n",
    "    plt.figure(figsize=(10,7), dpi=300)\n",
    "    ax = df_pct.plot(kind='bar', stacked=True, color=colors)\n",
    "\n",
    "    plt.ylabel('Percentage within split')\n",
    "    plt.title('Protein Families Distribution Across Splits')\n",
    "\n",
    "    plt.legend(title='Protein Family', loc='upper center',\n",
    "           bbox_to_anchor=(0.49, -0.55),  # below plot\n",
    "           fontsize=4, title_fontsize='small', ncol=4)\n",
    "    plt.subplots_adjust(bottom=0.55)  # add space below plot for legend\n",
    "\n",
    "    plt.savefig('../data/train_distribution.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "plot_protein_family_distribution(train_df, val_df, test_df)"
   ],
   "id": "ca5ab6cc28520062",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_df",
   "id": "1ce89cb8904072f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## redundancy reduction nontox",
   "id": "94e468e646b3fe47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!mmseqs easy-cluster ../data/raw/nontox.fasta ../data/mmseqs/nontox/cluster ../data/mmseqs/nontox/tmp --min-seq-id 0.9",
   "id": "8b2ff29b397c901f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rep_seqs = []\n",
    "\n",
    "nontox_dir = os.path.join(mmseqs_base_dir, \"nontox\")\n",
    "if os.path.isdir(nontox_dir):\n",
    "    rep_fasta = os.path.join(nontox_dir, \"cluster_rep_seq.fasta\")\n",
    "    if os.path.exists(rep_fasta):\n",
    "        for record in SeqIO.parse(rep_fasta, \"fasta\"):\n",
    "            rep_seqs.append({\n",
    "                \"Entry\": record.id,\n",
    "                \"Sequence\": str(record.seq),\n",
    "            })\n",
    "\n",
    "# Create DataFrame\n",
    "rep_df = pd.DataFrame(rep_seqs)\n",
    "rep_df"
   ],
   "id": "3e1b8643f46f99de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split into 70% train and 30% temp\n",
    "nontox_train_df, nontox_temp_df = train_test_split(rep_df, test_size=0.30, shuffle=True, random_state=42)\n",
    "\n",
    "# Split temp into 15% val and 15% test\n",
    "nontox_val_df, nontox_test_df = train_test_split(nontox_temp_df, test_size=0.50, shuffle=True, random_state=42)\n",
    "print_split_sizes(nontox_train_df,nontox_val_df,nontox_test_df,rep_df)"
   ],
   "id": "85c1e32b06b3ec49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## generate final training data\n",
    "### merge tox and nontox"
   ],
   "id": "289aba47bb1b5cb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nontox_train_df['Protein families'] = 'nontox'\n",
    "nontox_val_df['Protein families'] = 'nontox'\n",
    "nontox_test_df['Protein families'] = 'nontox'\n",
    "\n",
    "# Add 'Split' column to each dataframe\n",
    "train_df['Split'] = 'train'\n",
    "val_df['Split'] = 'val'\n",
    "test_df['Split'] = 'test'\n",
    "\n",
    "nontox_train_df['Split'] = 'train'\n",
    "nontox_val_df['Split'] = 'val'\n",
    "nontox_test_df['Split'] = 'test'\n",
    "\n",
    "# Concatenate all dataframes\n",
    "training_data = pd.concat([\n",
    "    train_df, val_df, test_df,\n",
    "    nontox_train_df, nontox_val_df, nontox_test_df\n",
    "], ignore_index=True)\n",
    "\n",
    "training_data"
   ],
   "id": "8f6ba2f3ad463eaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_data = pd.read_csv(\"../data/interm/training_data.csv\")\n",
    "len(training_data[\"Protein families\"].unique())"
   ],
   "id": "b5126210464c2eb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "training_data.to_csv(\"../data/interm/training_data.csv\", index=False)",
   "id": "eda483dea8601afe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test = training_data.copy()\n",
    "test[\"Length\"] = test[\"Sequence\"].str.len()\n",
    "\n",
    "long_sequences = test[test[\"Length\"] > 10000]\n",
    "\n",
    "print(long_sequences[[\"Entry\", \"Length\"]])\n",
    "\n",
    "# Plot der Längenverteilung\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(test[\"Length\"], bins=100, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Sequence Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Protein Sequence Lengths\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "bcb32d41d4efba1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "\n",
    "NUM_CHUNKS = 20\n",
    "total      = len(training_data)\n",
    "chunk_size = (total + NUM_CHUNKS - 1) // NUM_CHUNKS   # ceiling division\n",
    "\n",
    "for part in range(NUM_CHUNKS):\n",
    "    start = part * chunk_size\n",
    "    end   = min(start + chunk_size, total)\n",
    "    if start >= total:            # nothing left\n",
    "        break\n",
    "\n",
    "    chunk = training_data.iloc[start:end]\n",
    "    fasta_path = f\"../data/interm/training_data_part_{part+1}.fasta\"\n",
    "    write_fasta(chunk, fasta_path)\n",
    "    print(f\"✓ part {part+1:2d}: {len(chunk):>5} seq → {fasta_path} → {embed_path}\")\n",
    "\n",
    "    embed_path = f\"../data/interm/training_embeds_{part+1}.h5\"\n",
    "    subprocess.run(\n",
    "        [\n",
    "            \"python\", \"../generate_embeds.py\",\n",
    "            \"-i\", fasta_path,\n",
    "            \"-o\", embed_path,\n",
    "            \"--per-protein\",\n",
    "            \"--max-batch\", \"1\",\n",
    "            \"--max-residues\", \"1000\",\n",
    "            \"--max-seq-len\", \"500\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )\n"
   ],
   "id": "1f538605706b1388",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## generate embeddings",
   "id": "457dab55b288feef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "56137bcbc55d7e2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f89e3e021fb922c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
